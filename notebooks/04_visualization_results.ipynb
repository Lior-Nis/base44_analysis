{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# Base44 Phenomenon Analysis - Visualization Results\n",
    "\n",
    "This notebook creates comprehensive visualizations and interactive dashboards for the Base44 phenomenon analysis.\n",
    "\n",
    "## Visualization Objectives\n",
    "1. Create publication-ready charts and graphs\n",
    "2. Generate interactive dashboards for exploration\n",
    "3. Produce visual summaries of key findings\n",
    "4. Build comprehensive visualization portfolio\n",
    "5. Export visualizations for academic paper and presentations\n",
    "\n",
    "## Visualization Categories\n",
    "- **Distribution Charts**: Purpose, industry, complexity distributions\n",
    "- **Quality Analysis**: Quality metrics across categories\n",
    "- **Relationship Analysis**: Correlations and patterns\n",
    "- **Trend Analysis**: Evolution and patterns over time\n",
    "- **Comparative Analysis**: Benchmarking and comparisons\n",
    "- **Network Analysis**: Ecosystem relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from visualizer import Base44Visualizer\n",
    "\n",
    "# Import additional visualization libraries\n",
    "from wordcloud import WordCloud\n",
    "import networkx as nx\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set high DPI for better quality plots\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Visualization analysis started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data",
   "metadata": {},
   "source": [
    "## 1. Load All Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-all-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the visualizer\n",
    "visualizer = Base44Visualizer(output_dir='../results/figures')\n",
    "\n",
    "# Load all available data\n",
    "try:\n",
    "    apps_df, analysis_df, quality_df = visualizer.load_data()\n",
    "    \n",
    "    if not apps_df.empty and not analysis_df.empty and not quality_df.empty:\n",
    "        print(f\"✓ Successfully loaded all data:\")\n",
    "        print(f\"  • Applications: {len(apps_df)} records\")\n",
    "        print(f\"  • Analysis: {len(analysis_df)} records\")\n",
    "        print(f\"  • Quality: {len(quality_df)} records\")\n",
    "        \n",
    "        # Create merged dataset for comprehensive analysis\n",
    "        merged_df = pd.merge(analysis_df, quality_df, left_on='name', right_on='app_name', how='inner')\n",
    "        merged_df = pd.merge(merged_df, apps_df[['name', 'url', 'source', 'description']], \n",
    "                           left_on='name', right_on='name', how='left')\n",
    "        \n",
    "        print(f\"  • Merged dataset: {len(merged_df)} records\")\n",
    "        \n",
    "        # Display data overview\n",
    "        print(\"\\n=== Data Overview ===\")\n",
    "        print(f\"Available columns in merged dataset:\")\n",
    "        for col in merged_df.columns:\n",
    "            print(f\"  • {col}\")\n",
    "        \n",
    "        data_available = True\n",
    "    else:\n",
    "        print(\"⚠️ Some data files are missing or empty\")\n",
    "        print(\"Please run the previous notebooks to generate the required data\")\n",
    "        data_available = False\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading data: {e}\")\n",
    "    print(\"Please ensure all previous notebooks have been run successfully\")\n",
    "    data_available = False\n",
    "    apps_df = pd.DataFrame()\n",
    "    analysis_df = pd.DataFrame()\n",
    "    quality_df = pd.DataFrame()\n",
    "    merged_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-dashboard",
   "metadata": {},
   "source": [
    "## 2. Executive Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-summary-dashboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_available:\n",
    "    print(\"=== Creating Executive Summary Dashboard ===\")\n",
    "    \n",
    "    # Create executive summary dashboard\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=3,\n",
    "        subplot_titles=(\n",
    "            'Application Purposes', 'Industry Distribution', 'Quality Overview',\n",
    "            'Complexity vs Quality', 'Feature Usage', 'Sentiment Analysis',\n",
    "            'Success Metrics', 'Platform Adoption', 'Key Performance Indicators'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{\"type\": \"pie\"}, {\"type\": \"bar\"}, {\"type\": \"scatter\"}],\n",
    "            [{\"type\": \"scatter\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "            [{\"type\": \"bar\"}, {\"type\": \"pie\"}, {\"type\": \"indicator\"}]\n",
    "        ],\n",
    "        vertical_spacing=0.12,\n",
    "        horizontal_spacing=0.08\n",
    "    )\n",
    "    \n",
    "    # 1. Application Purposes (Pie)\n",
    "    purpose_counts = merged_df['purpose_category'].value_counts()\n",
    "    fig.add_trace(go.Pie(\n",
    "        labels=purpose_counts.index,\n",
    "        values=purpose_counts.values,\n",
    "        name=\"Purposes\"\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # 2. Industry Distribution (Bar)\n",
    "    industry_counts = merged_df['industry_category'].value_counts().head(8)\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=industry_counts.values,\n",
    "        y=industry_counts.index,\n",
    "        orientation='h',\n",
    "        name=\"Industries\"\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # 3. Quality Overview (Scatter)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=merged_df['overall_quality_score'],\n",
    "        y=merged_df['completeness_score'],\n",
    "        mode='markers',\n",
    "        marker=dict(color=merged_df['complexity_score'], colorscale='Viridis', \n",
    "                   size=8, opacity=0.7),\n",
    "        text=merged_df['name'],\n",
    "        name=\"Quality vs Completeness\"\n",
    "    ), row=1, col=3)\n",
    "    \n",
    "    # 4. Complexity vs Quality (Scatter)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=merged_df['complexity_score'],\n",
    "        y=merged_df['overall_quality_score'],\n",
    "        mode='markers',\n",
    "        marker=dict(color=merged_df['feature_count'], colorscale='Plasma',\n",
    "                   size=10, opacity=0.6),\n",
    "        text=merged_df['name'],\n",
    "        name=\"Complexity vs Quality\"\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # 5. Feature Usage (Bar)\n",
    "    feature_stats = merged_df.groupby('purpose_category')['feature_count'].mean().sort_values(ascending=False)\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=feature_stats.index,\n",
    "        y=feature_stats.values,\n",
    "        name=\"Avg Features by Purpose\"\n",
    "    ), row=2, col=2)\n",
    "    \n",
    "    # 6. Sentiment Analysis (Bar)\n",
    "    sentiment_categories = []\n",
    "    for sentiment in merged_df['description_sentiment']:\n",
    "        if sentiment > 0.1:\n",
    "            sentiment_categories.append('Positive')\n",
    "        elif sentiment < -0.1:\n",
    "            sentiment_categories.append('Negative')\n",
    "        else:\n",
    "            sentiment_categories.append('Neutral')\n",
    "    \n",
    "    sentiment_counts = pd.Series(sentiment_categories).value_counts()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=sentiment_counts.index,\n",
    "        y=sentiment_counts.values,\n",
    "        marker_color=['green', 'gray', 'red'],\n",
    "        name=\"Sentiment Distribution\"\n",
    "    ), row=2, col=3)\n",
    "    \n",
    "    # 7. Success Metrics (Bar)\n",
    "    success_metrics = {\n",
    "        'High Quality (≥7)': (merged_df['overall_quality_score'] >= 7).sum(),\n",
    "        'High Adoption (≥6)': (merged_df['adoption_score'] >= 6).sum(),\n",
    "        'Professional (≥6)': (merged_df['professional_score'] >= 6).sum(),\n",
    "        'Fast Development (≥7)': (merged_df['time_to_market_score'] >= 7).sum()\n",
    "    }\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(success_metrics.keys()),\n",
    "        y=list(success_metrics.values()),\n",
    "        name=\"Success Metrics Count\"\n",
    "    ), row=3, col=1)\n",
    "    \n",
    "    # 8. Platform Adoption (Pie)\n",
    "    source_counts = apps_df['source'].value_counts()\n",
    "    fig.add_trace(go.Pie(\n",
    "        labels=source_counts.index,\n",
    "        values=source_counts.values,\n",
    "        name=\"Data Sources\"\n",
    "    ), row=3, col=2)\n",
    "    \n",
    "    # 9. KPIs (Indicators - will use text instead)\n",
    "    avg_quality = merged_df['overall_quality_score'].mean()\n",
    "    total_apps = len(merged_df)\n",
    "    high_quality_pct = (merged_df['overall_quality_score'] >= 7).sum() / total_apps * 100\n",
    "    \n",
    "    kpi_text = f\"\"\"Total Apps: {total_apps}\n",
    "Avg Quality: {avg_quality:.1f}/10\n",
    "High Quality: {high_quality_pct:.1f}%\n",
    "Avg Features: {merged_df['feature_count'].mean():.1f}\n",
    "Positive Sentiment: {(merged_df['description_sentiment'] > 0.1).sum() / total_apps * 100:.1f}%\"\"\"\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        text=kpi_text,\n",
    "        xref=\"x9\", yref=\"y9\",\n",
    "        x=0.5, y=0.5,\n",
    "        showarrow=False,\n",
    "        font=dict(size=12),\n",
    "        align=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"Base44 Phenomenon Analysis - Executive Dashboard\",\n",
    "        title_x=0.5,\n",
    "        title_font_size=20,\n",
    "        height=1200,\n",
    "        showlegend=False,\n",
    "        font=dict(size=10)\n",
    "    )\n",
    "    \n",
    "    # Update axes titles\n",
    "    fig.update_xaxes(title_text=\"Quality Score\", row=1, col=3)\n",
    "    fig.update_yaxes(title_text=\"Completeness\", row=1, col=3)\n",
    "    fig.update_xaxes(title_text=\"Complexity\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Quality\", row=2, col=1)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Save dashboard\n",
    "    fig.write_html('../results/figures/executive_dashboard.html')\n",
    "    print(\"✓ Executive dashboard saved to results/figures/executive_dashboard.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-visualizations",
   "metadata": {},
   "source": [
    "## 3. Generate Individual Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-individual-charts",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_available:\n",
    "    print(\"=== Creating Individual Visualizations ===\")\n",
    "    \n",
    "    # 1. Purpose Distribution Chart\n",
    "    print(\"Creating purpose distribution chart...\")\n",
    "    purpose_fig = visualizer.create_purpose_distribution_chart(analysis_df)\n",
    "    purpose_fig.show()\n",
    "    purpose_fig.write_html('../results/figures/purpose_distribution.html')\n",
    "    \n",
    "    # 2. Industry Distribution Chart\n",
    "    print(\"Creating industry distribution chart...\")\n",
    "    industry_fig = visualizer.create_industry_distribution_chart(analysis_df)\n",
    "    industry_fig.show()\n",
    "    industry_fig.write_html('../results/figures/industry_distribution.html')\n",
    "    \n",
    "    # 3. Complexity vs Quality Scatter Plot\n",
    "    print(\"Creating complexity vs quality analysis...\")\n",
    "    complexity_fig = visualizer.create_complexity_vs_quality_scatter(analysis_df, quality_df)\n",
    "    complexity_fig.show()\n",
    "    complexity_fig.write_html('../results/figures/complexity_vs_quality.html')\n",
    "    \n",
    "    # 4. Quality Metrics Radar Chart\n",
    "    print(\"Creating quality metrics radar chart...\")\n",
    "    radar_fig = visualizer.create_quality_metrics_radar_chart(quality_df)\n",
    "    radar_fig.show()\n",
    "    radar_fig.write_html('../results/figures/quality_radar.html')\n",
    "    \n",
    "    # 5. Quality Distribution Histogram\n",
    "    print(\"Creating quality distribution histogram...\")\n",
    "    quality_hist_fig = visualizer.create_quality_distribution_histogram(quality_df)\n",
    "    quality_hist_fig.show()\n",
    "    quality_hist_fig.write_html('../results/figures/quality_histogram.html')\n",
    "    \n",
    "    print(\"\\n✓ Individual visualizations created and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-visualizations",
   "metadata": {},
   "source": [
    "## 4. Advanced Analysis Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-advanced-charts",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_available:\n",
    "    print(\"=== Creating Advanced Analysis Visualizations ===\")\n",
    "    \n",
    "    # 1. Feature Heatmap\n",
    "    print(\"Creating feature usage heatmap...\")\n",
    "    heatmap_fig = visualizer.create_feature_heatmap(apps_df)\n",
    "    heatmap_fig.show()\n",
    "    heatmap_fig.write_html('../results/figures/feature_heatmap.html')\n",
    "    \n",
    "    # 2. Development Speed Analysis\n",
    "    print(\"Creating development speed analysis...\")\n",
    "    speed_fig = visualizer.create_development_speed_analysis(analysis_df, quality_df)\n",
    "    speed_fig.show()\n",
    "    speed_fig.write_html('../results/figures/development_speed.html')\n",
    "    \n",
    "    # 3. Sentiment Analysis Chart\n",
    "    print(\"Creating sentiment analysis chart...\")\n",
    "    sentiment_fig = visualizer.create_sentiment_analysis_chart(analysis_df)\n",
    "    sentiment_fig.show()\n",
    "    sentiment_fig.write_html('../results/figures/sentiment_analysis.html')\n",
    "    \n",
    "    # 4. Time Series Analysis\n",
    "    print(\"Creating time series analysis...\")\n",
    "    timeseries_fig = visualizer.create_time_series_analysis(apps_df)\n",
    "    timeseries_fig.show()\n",
    "    timeseries_fig.write_html('../results/figures/time_series.html')\n",
    "    \n",
    "    # 5. Success Metrics Dashboard\n",
    "    print(\"Creating success metrics dashboard...\")\n",
    "    success_fig = visualizer.create_success_metrics_dashboard(analysis_df, quality_df)\n",
    "    success_fig.show()\n",
    "    success_fig.write_html('../results/figures/success_dashboard.html')\n",
    "    \n",
    "    print(\"\\n✓ Advanced visualizations created and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-visualizations",
   "metadata": {},
   "source": [
    "## 5. Static Visualizations for Publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-static-charts",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_available:\n",
    "    print(\"=== Creating Static Visualizations for Publications ===\")\n",
    "    \n",
    "    # Set publication style\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 14,\n",
    "        'axes.labelsize': 12,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10,\n",
    "        'legend.fontsize': 10,\n",
    "        'figure.titlesize': 16\n",
    "    })\n",
    "    \n",
    "    # 1. Publication-ready Purpose and Industry Analysis\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Base44 Application Ecosystem Analysis', fontsize=18, y=0.98)\n",
    "    \n",
    "    # Purpose distribution\n",
    "    purpose_counts = merged_df['purpose_category'].value_counts()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(purpose_counts)))\n",
    "    wedges, texts, autotexts = ax1.pie(purpose_counts.values, labels=purpose_counts.index, \n",
    "                                      autopct='%1.1f%%', startangle=90, colors=colors)\n",
    "    ax1.set_title('A) Application Purpose Distribution', fontweight='bold')\n",
    "    \n",
    "    # Industry distribution (top 8)\n",
    "    industry_counts = merged_df['industry_category'].value_counts().head(8)\n",
    "    bars = ax2.barh(range(len(industry_counts)), industry_counts.values, \n",
    "                   color=plt.cm.viridis(np.linspace(0, 1, len(industry_counts))))\n",
    "    ax2.set_yticks(range(len(industry_counts)))\n",
    "    ax2.set_yticklabels(industry_counts.index)\n",
    "    ax2.set_xlabel('Number of Applications')\n",
    "    ax2.set_title('B) Industry Distribution', fontweight='bold')\n",
    "    ax2.invert_yaxis()\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        ax2.text(width + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "                f'{int(width)}', ha='left', va='center', fontsize=9)\n",
    "    \n",
    "    # Quality vs Complexity scatter\n",
    "    scatter = ax3.scatter(merged_df['complexity_score'], merged_df['overall_quality_score'],\n",
    "                         c=merged_df['feature_count'], cmap='plasma', alpha=0.6, s=60)\n",
    "    ax3.set_xlabel('Complexity Score')\n",
    "    ax3.set_ylabel('Overall Quality Score')\n",
    "    ax3.set_title('C) Complexity vs Quality Relationship', fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add correlation line\n",
    "    z = np.polyfit(merged_df['complexity_score'], merged_df['overall_quality_score'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax3.plot(merged_df['complexity_score'], p(merged_df['complexity_score']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    corr = merged_df['complexity_score'].corr(merged_df['overall_quality_score'])\n",
    "    ax3.text(0.05, 0.95, f'r = {corr:.3f}', transform=ax3.transAxes, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), fontsize=10)\n",
    "    \n",
    "    # Colorbar for scatter plot\n",
    "    cbar = plt.colorbar(scatter, ax=ax3)\n",
    "    cbar.set_label('Feature Count', rotation=270, labelpad=15)\n",
    "    \n",
    "    # Quality metrics comparison\n",
    "    quality_metrics = ['completeness_score', 'professional_score', 'adoption_score', \n",
    "                      'time_to_market_score', 'longevity_score']\n",
    "    metric_labels = ['Completeness', 'Professional', 'Adoption', 'Time to Market', 'Longevity']\n",
    "    metric_means = [merged_df[metric].mean() for metric in quality_metrics]\n",
    "    \n",
    "    bars = ax4.bar(metric_labels, metric_means, color=plt.cm.coolwarm(np.linspace(0.2, 0.8, len(metric_means))))\n",
    "    ax4.set_ylabel('Average Score')\n",
    "    ax4.set_title('D) Quality Metrics Overview', fontweight='bold')\n",
    "    ax4.set_ylim(0, 10)\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, metric_means):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                f'{value:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/figures/publication_figure_1.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Quality Analysis Publication Figure\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Base44 Application Quality Analysis', fontsize=18, y=0.98)\n",
    "    \n",
    "    # Quality distribution histogram\n",
    "    ax1.hist(merged_df['overall_quality_score'], bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax1.axvline(merged_df['overall_quality_score'].mean(), color='red', linestyle='--', \n",
    "               label=f'Mean: {merged_df[\"overall_quality_score\"].mean():.2f}')\n",
    "    ax1.axvline(merged_df['overall_quality_score'].median(), color='green', linestyle='--', \n",
    "               label=f'Median: {merged_df[\"overall_quality_score\"].median():.2f}')\n",
    "    ax1.set_xlabel('Overall Quality Score')\n",
    "    ax1.set_ylabel('Number of Applications')\n",
    "    ax1.set_title('A) Quality Score Distribution', fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Quality by purpose boxplot\n",
    "    purpose_categories = merged_df['purpose_category'].unique()\n",
    "    quality_by_purpose = [merged_df[merged_df['purpose_category'] == cat]['overall_quality_score'] \n",
    "                         for cat in purpose_categories]\n",
    "    \n",
    "    bp = ax2.boxplot(quality_by_purpose, labels=purpose_categories, patch_artist=True)\n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, len(bp['boxes'])))\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    ax2.set_ylabel('Overall Quality Score')\n",
    "    ax2.set_title('B) Quality Distribution by Purpose', fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Success factors correlation\n",
    "    quality_features = ['completeness_score', 'professional_score', 'adoption_score', \n",
    "                       'replacement_success_score', 'time_to_market_score', 'longevity_score']\n",
    "    correlations = merged_df[quality_features].corrwith(merged_df['overall_quality_score']).sort_values(ascending=True)\n",
    "    \n",
    "    bars = ax3.barh(range(len(correlations)), correlations.values, \n",
    "                   color=['red' if x < 0 else 'green' for x in correlations.values])\n",
    "    ax3.set_yticks(range(len(correlations)))\n",
    "    ax3.set_yticklabels([label.replace('_', ' ').title() for label in correlations.index])\n",
    "    ax3.set_xlabel('Correlation with Overall Quality')\n",
    "    ax3.set_title('C) Quality Success Factors', fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.axvline(0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # Add correlation values\n",
    "    for i, (bar, value) in enumerate(zip(bars, correlations.values)):\n",
    "        ax3.text(value + (0.01 if value >= 0 else -0.01), bar.get_y() + bar.get_height()/2, \n",
    "                f'{value:.3f}', ha='left' if value >= 0 else 'right', va='center', fontsize=9)\n",
    "    \n",
    "    # Feature count vs quality\n",
    "    scatter = ax4.scatter(merged_df['feature_count'], merged_df['overall_quality_score'],\n",
    "                         c=merged_df['complexity_score'], cmap='viridis', alpha=0.6, s=60)\n",
    "    ax4.set_xlabel('Number of Features')\n",
    "    ax4.set_ylabel('Overall Quality Score')\n",
    "    ax4.set_title('D) Features vs Quality Relationship', fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(merged_df['feature_count'], merged_df['overall_quality_score'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax4.plot(merged_df['feature_count'], p(merged_df['feature_count']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax4)\n",
    "    cbar.set_label('Complexity Score', rotation=270, labelpad=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/figures/publication_figure_2.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Publication-ready static visualizations created\")\n",
    "    print(\"  • publication_figure_1.png - Ecosystem Analysis\")\n",
    "    print(\"  • publication_figure_2.png - Quality Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "word-cloud-network",
   "metadata": {},
   "source": [
    "## 6. Word Cloud and Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-wordcloud-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_available:\n",
    "    print(\"=== Creating Word Cloud and Network Visualizations ===\")\n",
    "    \n",
    "    # 1. Create Word Cloud\n",
    "    print(\"Creating word cloud from application descriptions...\")\n",
    "    visualizer.create_word_cloud(apps_df)\n",
    "    \n",
    "    # 2. Create Network Graph\n",
    "    print(\"Creating network graph of application ecosystem...\")\n",
    "    visualizer.create_network_graph(apps_df)\n",
    "    \n",
    "    # 3. Additional Word Clouds by Category\n",
    "    print(\"Creating category-specific word clouds...\")\n",
    "    \n",
    "    # Word cloud by purpose\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Word Clouds by Application Purpose', fontsize=16)\n",
    "    \n",
    "    purposes = merged_df['purpose_category'].unique()[:6]  # Top 6 purposes\n",
    "    \n",
    "    for i, purpose in enumerate(purposes):\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "        \n",
    "        purpose_descriptions = merged_df[merged_df['purpose_category'] == purpose]['description_x'].dropna()\n",
    "        if len(purpose_descriptions) > 0:\n",
    "            text = ' '.join(purpose_descriptions.astype(str))\n",
    "            \n",
    "            if text.strip():  # Only create wordcloud if there's text\n",
    "                wordcloud = WordCloud(\n",
    "                    width=400, height=300,\n",
    "                    background_color='white',\n",
    "                    colormap='viridis',\n",
    "                    max_words=50\n",
    "                ).generate(text)\n",
    "                \n",
    "                axes[row, col].imshow(wordcloud, interpolation='bilinear')\n",
    "                axes[row, col].set_title(f'{purpose}\\n({len(purpose_descriptions)} apps)', fontsize=12)\n",
    "                axes[row, col].axis('off')\n",
    "            else:\n",
    "                axes[row, col].text(0.5, 0.5, 'No text data', ha='center', va='center', transform=axes[row, col].transAxes)\n",
    "                axes[row, col].set_title(f'{purpose}\\n(No data)', fontsize=12)\n",
    "                axes[row, col].axis('off')\n",
    "        else:\n",
    "            axes[row, col].text(0.5, 0.5, 'No descriptions', ha='center', va='center', transform=axes[row, col].transAxes)\n",
    "            axes[row, col].set_title(f'{purpose}\\n(No data)', fontsize=12)\n",
    "            axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/figures/wordclouds_by_purpose.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Word cloud and network visualizations created\")\n",
    "    print(\"  • word_cloud.png - Overall word cloud\")\n",
    "    print(\"  • network_graph.png - Ecosystem network\")\n",
    "    print(\"  • wordclouds_by_purpose.png - Purpose-specific word clouds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interactive-dashboard",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Interactive Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-interactive-dashboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_available:\n",
    "    print(\"=== Creating Comprehensive Interactive Dashboard ===\")\n",
    "    \n",
    "    # Create comprehensive dashboard with multiple tabs/sections\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.graph_objects as go\n",
    "    \n",
    "    # Main dashboard with 6 panels\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Application Purpose & Industry Overview',\n",
    "            'Quality Metrics Analysis', \n",
    "            'Complexity vs Quality Relationship',\n",
    "            'Success Metrics by Category',\n",
    "            'Platform Adoption & Growth',\n",
    "            'Key Performance Indicators'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{\"secondary_y\": True}, {\"type\": \"scatter\"}],\n",
    "            [{\"type\": \"scatter\"}, {\"type\": \"bar\"}],\n",
    "            [{\"type\": \"scatter\"}, {\"type\": \"indicator\"}]\n",
    "        ],\n",
    "        vertical_spacing=0.08,\n",
    "        horizontal_spacing=0.10\n",
    "    )\n",
    "    \n",
    "    # Panel 1: Purpose & Industry Overview (Dual axis)\n",
    "    purpose_counts = merged_df['purpose_category'].value_counts()\n",
    "    industry_counts = merged_df['industry_category'].value_counts().head(6)\n",
    "    \n",
    "    # Purpose bars\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=purpose_counts.index, y=purpose_counts.values, \n",
    "               name=\"Purpose Count\", marker_color='lightblue'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Industry line on secondary y-axis\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=industry_counts.index, y=industry_counts.values, \n",
    "                  mode='lines+markers', name=\"Industry Count\", \n",
    "                  line=dict(color='red'), yaxis='y2'),\n",
    "        row=1, col=1, secondary_y=True\n",
    "    )\n",
    "    \n",
    "    # Panel 2: Quality Metrics Radar\n",
    "    avg_metrics = merged_df[['completeness_score', 'professional_score', \n",
    "                           'adoption_score', 'time_to_market_score', \n",
    "                           'longevity_score']].mean()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatterpolar(\n",
    "            r=avg_metrics.values,\n",
    "            theta=['Completeness', 'Professional', 'Adoption', 'Time to Market', 'Longevity'],\n",
    "            fill='toself',\n",
    "            name='Avg Quality Metrics'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Panel 3: Complexity vs Quality with size by features\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=merged_df['complexity_score'],\n",
    "            y=merged_df['overall_quality_score'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=merged_df['feature_count'] * 2,\n",
    "                color=merged_df['description_sentiment'],\n",
    "                colorscale='RdYlGn',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"Sentiment\")\n",
    "            ),\n",
    "            text=merged_df['name'],\n",
    "            hovertemplate='<b>%{text}</b><br>' +\n",
    "                         'Complexity: %{x}<br>' +\n",
    "                         'Quality: %{y}<br>' +\n",
    "                         'Features: %{marker.size}<br>' +\n",
    "                         '<extra></extra>',\n",
    "            name='Apps'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Panel 4: Success Metrics by Purpose\n",
    "    success_by_purpose = merged_df.groupby('purpose_category').agg({\n",
    "        'overall_quality_score': 'mean',\n",
    "        'adoption_score': 'mean',\n",
    "        'professional_score': 'mean'\n",
    "    })\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(x=success_by_purpose.index, y=success_by_purpose['overall_quality_score'],\n",
    "               name='Quality', marker_color='lightcoral'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(x=success_by_purpose.index, y=success_by_purpose['adoption_score'],\n",
    "               name='Adoption', marker_color='lightgreen'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Panel 5: Platform Growth (Mock time series)\n",
    "    dates = pd.date_range('2023-01-01', periods=12, freq='M')\n",
    "    cumulative_apps = np.cumsum(np.random.poisson(3, 12))\n",
    "    quality_trend = 5 + np.random.normal(0, 0.5, 12).cumsum()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=dates, y=cumulative_apps, mode='lines+markers',\n",
    "                  name='Cumulative Apps', line=dict(color='blue')),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=dates, y=quality_trend, mode='lines+markers',\n",
    "                  name='Quality Trend', line=dict(color='green'), yaxis='y7'),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    # Panel 6: KPI Indicators\n",
    "    total_apps = len(merged_df)\n",
    "    avg_quality = merged_df['overall_quality_score'].mean()\n",
    "    high_quality_pct = (merged_df['overall_quality_score'] >= 7).sum() / total_apps * 100\n",
    "    avg_features = merged_df['feature_count'].mean()\n",
    "    \n",
    "    # Create KPI text\n",
    "    kpi_text = f\"\"\"<b>Key Performance Indicators</b><br><br>\n",
    "📊 Total Applications: {total_apps}<br>\n",
    "⭐ Average Quality: {avg_quality:.1f}/10<br>\n",
    "🏆 High Quality Apps: {high_quality_pct:.1f}%<br>\n",
    "🔧 Average Features: {avg_features:.1f}<br>\n",
    "😊 Positive Sentiment: {(merged_df['description_sentiment'] > 0.1).sum() / total_apps * 100:.1f}%<br>\n",
    "🚀 Fast Development: {(merged_df['time_to_market_score'] >= 7).sum() / total_apps * 100:.1f}%<br>\n",
    "💼 Professional Apps: {(merged_df['professional_score'] >= 6).sum() / total_apps * 100:.1f}%\"\"\"\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        text=kpi_text,\n",
    "        xref=\"x6\", yref=\"y6\",\n",
    "        x=0.1, y=0.9,\n",
    "        showarrow=False,\n",
    "        font=dict(size=12),\n",
    "        align=\"left\",\n",
    "        bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "        bordercolor=\"gray\",\n",
    "        borderwidth=1\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': \"Base44 Phenomenon Analysis - Comprehensive Dashboard\",\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center',\n",
    "            'font': {'size': 24}\n",
    "        },\n",
    "        height=1400,\n",
    "        showlegend=True,\n",
    "        legend=dict(x=1.02, y=1),\n",
    "        font=dict(size=10)\n",
    "    )\n",
    "    \n",
    "    # Update axes titles\n",
    "    fig.update_xaxes(title_text=\"Purpose Category\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Complexity Score\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Quality Score\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Purpose Category\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Average Score\", row=2, col=2)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Cumulative Apps\", row=3, col=1)\n",
    "    \n",
    "    # Show and save\n",
    "    fig.show()\n",
    "    fig.write_html('../results/figures/comprehensive_dashboard.html')\n",
    "    \n",
    "    print(\"\\n✓ Comprehensive interactive dashboard created\")\n",
    "    print(\"  • comprehensive_dashboard.html - Full interactive dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate-all-visualizations",
   "metadata": {},
   "source": [
    "## 8. Generate All Visualizations with Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-complete-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_available:\n",
    "    print(\"=== Running Complete Visualization Generation ===\")\n",
    "    \n",
    "    # Use the visualizer to generate all standard visualizations\n",
    "    visualizer.generate_all_visualizations()\n",
    "    \n",
    "    print(\"\\n=== VISUALIZATION SUMMARY ===\")\n",
    "    print(\"\\n📊 Interactive Visualizations Generated:\")\n",
    "    print(\"  • purpose_distribution.html - Application purpose breakdown\")\n",
    "    print(\"  • industry_distribution.html - Industry analysis\")\n",
    "    print(\"  • complexity_vs_quality.html - Relationship analysis\")\n",
    "    print(\"  • quality_radar.html - Quality metrics overview\")\n",
    "    print(\"  • feature_heatmap.html - Feature usage patterns\")\n",
    "    print(\"  • quality_histogram.html - Quality distribution\")\n",
    "    print(\"  • development_speed.html - Development speed analysis\")\n",
    "    print(\"  • sentiment_analysis.html - Sentiment patterns\")\n",
    "    print(\"  • time_series.html - Platform growth\")\n",
    "    print(\"  • success_dashboard.html - Success metrics\")\n",
    "    print(\"  • executive_dashboard.html - Executive summary\")\n",
    "    print(\"  • comprehensive_dashboard.html - Full analysis dashboard\")\n",
    "    \n",
    "    print(\"\\n📈 Static Visualizations Generated:\")\n",
    "    print(\"  • publication_figure_1.png - Ecosystem analysis (publication-ready)\")\n",
    "    print(\"  • publication_figure_2.png - Quality analysis (publication-ready)\")\n",
    "    print(\"  • word_cloud.png - Application descriptions word cloud\")\n",
    "    print(\"  • network_graph.png - Ecosystem network visualization\")\n",
    "    print(\"  • wordclouds_by_purpose.png - Purpose-specific word clouds\")\n",
    "    \n",
    "    print(\"\\n📄 Summary Files:\")\n",
    "    print(\"  • visualization_summary.html - Complete visualization index\")\n",
    "    \n",
    "    print(\"\\n✅ ALL VISUALIZATIONS COMPLETED!\")\n",
    "    print(\"\\nFiles are saved in the 'results/figures/' directory\")\n",
    "    print(\"Open 'visualization_summary.html' for a complete overview\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Cannot generate visualizations without data\")\n",
    "    print(\"Please run the previous notebooks to generate the required data files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-insights",
   "metadata": {},
   "source": [
    "## 9. Key Visualization Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summarize-insights",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_available:\n",
    "    print(\"=== KEY INSIGHTS FROM VISUALIZATIONS ===\")\n",
    "    \n",
    "    # Extract key insights from the data\n",
    "    total_apps = len(merged_df)\n",
    "    \n",
    "    # Purpose insights\n",
    "    top_purpose = merged_df['purpose_category'].value_counts().index[0]\n",
    "    top_purpose_pct = merged_df['purpose_category'].value_counts().iloc[0] / total_apps * 100\n",
    "    \n",
    "    # Industry insights\n",
    "    top_industry = merged_df['industry_category'].value_counts().index[0]\n",
    "    top_industry_pct = merged_df['industry_category'].value_counts().iloc[0] / total_apps * 100\n",
    "    \n",
    "    # Quality insights\n",
    "    avg_quality = merged_df['overall_quality_score'].mean()\n",
    "    quality_std = merged_df['overall_quality_score'].std()\n",
    "    high_quality_pct = (merged_df['overall_quality_score'] >= 7).sum() / total_apps * 100\n",
    "    \n",
    "    # Complexity insights\n",
    "    avg_complexity = merged_df['complexity_score'].mean()\n",
    "    complexity_quality_corr = merged_df['complexity_score'].corr(merged_df['overall_quality_score'])\n",
    "    \n",
    "    # Feature insights\n",
    "    avg_features = merged_df['feature_count'].mean()\n",
    "    max_features = merged_df['feature_count'].max()\n",
    "    \n",
    "    # Sentiment insights\n",
    "    positive_sentiment_pct = (merged_df['description_sentiment'] > 0.1).sum() / total_apps * 100\n",
    "    avg_sentiment = merged_df['description_sentiment'].mean()\n",
    "    \n",
    "    print(f\"\\n🎯 PURPOSE & INDUSTRY PATTERNS:\")\n",
    "    print(f\"   • Most common purpose: {top_purpose} ({top_purpose_pct:.1f}% of apps)\")\n",
    "    print(f\"   • Most active industry: {top_industry} ({top_industry_pct:.1f}% of apps)\")\n",
    "    print(f\"   • Purpose diversity: {merged_df['purpose_category'].nunique()} distinct categories\")\n",
    "    print(f\"   • Industry diversity: {merged_df['industry_category'].nunique()} distinct sectors\")\n",
    "    \n",
    "    print(f\"\\n📊 QUALITY & PERFORMANCE:\")\n",
    "    print(f\"   • Average quality score: {avg_quality:.2f}/10 (σ = {quality_std:.2f})\")\n",
    "    print(f\"   • High-quality applications: {high_quality_pct:.1f}% (≥7.0 score)\")\n",
    "    print(f\"   • Quality range: {merged_df['overall_quality_score'].min():.1f} - {merged_df['overall_quality_score'].max():.1f}\")\n",
    "    \n",
    "    # Identify quality leaders\n",
    "    quality_by_purpose = merged_df.groupby('purpose_category')['overall_quality_score'].mean().sort_values(ascending=False)\n",
    "    print(f\"   • Highest quality purpose: {quality_by_purpose.index[0]} ({quality_by_purpose.iloc[0]:.2f})\")\n",
    "    print(f\"   • Lowest quality purpose: {quality_by_purpose.index[-1]} ({quality_by_purpose.iloc[-1]:.2f})\")\n",
    "    \n",
    "    print(f\"\\n🔧 COMPLEXITY & FEATURES:\")\n",
    "    print(f\"   • Average complexity: {avg_complexity:.2f}/10\")\n",
    "    print(f\"   • Average features per app: {avg_features:.1f}\")\n",
    "    print(f\"   • Most feature-rich app: {max_features} features\")\n",
    "    print(f\"   • Complexity-quality correlation: r = {complexity_quality_corr:.3f}\")\n",
    "    \n",
    "    if abs(complexity_quality_corr) > 0.3:\n",
    "        direction = \"positively\" if complexity_quality_corr > 0 else \"negatively\"\n",
    "        print(f\"   • {direction.title()} correlated: {'more' if complexity_quality_corr > 0 else 'less'} complex apps tend to be higher quality\")\n",
    "    else:\n",
    "        print(f\"   • Weak correlation: complexity doesn't strongly predict quality\")\n",
    "    \n",
    "    print(f\"\\n💭 SENTIMENT & RECEPTION:\")\n",
    "    print(f\"   • Positive sentiment: {positive_sentiment_pct:.1f}% of descriptions\")\n",
    "    print(f\"   • Average sentiment: {avg_sentiment:.3f} (scale: -1 to +1)\")\n",
    "    \n",
    "    if avg_sentiment > 0.1:\n",
    "        print(f\"   • Overall positive reception of Base44 applications\")\n",
    "    elif avg_sentiment < -0.1:\n",
    "        print(f\"   • Overall negative reception of Base44 applications\")\n",
    "    else:\n",
    "        print(f\"   • Neutral sentiment towards Base44 applications\")\n",
    "    \n",
    "    print(f\"\\n🚀 SUCCESS FACTORS:\")\n",
    "    \n",
    "    # Identify success correlations\n",
    "    success_correlations = merged_df[[\n",
    "        'completeness_score', 'professional_score', 'adoption_score', \n",
    "        'time_to_market_score', 'longevity_score'\n",
    "    ]].corrwith(merged_df['overall_quality_score']).sort_values(ascending=False)\n",
    "    \n",
    "    print(f\"   • Strongest success factor: {success_correlations.index[0].replace('_', ' ').title()}\")\n",
    "    print(f\"     (r = {success_correlations.iloc[0]:.3f})\")\n",
    "    print(f\"   • Weakest factor: {success_correlations.index[-1].replace('_', ' ').title()}\")\n",
    "    print(f\"     (r = {success_correlations.iloc[-1]:.3f})\")\n",
    "    \n",
    "    # Platform performance metrics\n",
    "    fast_development_pct = (merged_df['time_to_market_score'] >= 7).sum() / total_apps * 100\n",
    "    professional_pct = (merged_df['professional_score'] >= 6).sum() / total_apps * 100\n",
    "    high_adoption_pct = (merged_df['adoption_score'] >= 6).sum() / total_apps * 100\n",
    "    \n",
    "    print(f\"\\n🏆 PLATFORM PERFORMANCE:\")\n",
    "    print(f\"   • Fast development: {fast_development_pct:.1f}% of apps (≥7.0 score)\")\n",
    "    print(f\"   • Professional quality: {professional_pct:.1f}% of apps (≥6.0 score)\")\n",
    "    print(f\"   • High adoption: {high_adoption_pct:.1f}% of apps (≥6.0 score)\")\n",
    "    \n",
    "    # Data source insights\n",
    "    source_distribution = apps_df['source'].value_counts()\n",
    "    print(f\"\\n📈 DATA SOURCE INSIGHTS:\")\n",
    "    for source, count in source_distribution.items():\n",
    "        pct = count / len(apps_df) * 100\n",
    "        print(f\"   • {source}: {count} apps ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n🎯 VISUALIZATION RECOMMENDATIONS:\")\n",
    "    \n",
    "    if high_quality_pct < 30:\n",
    "        print(f\"   • Focus on quality improvement - only {high_quality_pct:.1f}% achieve high quality\")\n",
    "    \n",
    "    if positive_sentiment_pct > 70:\n",
    "        print(f\"   • Leverage positive sentiment ({positive_sentiment_pct:.1f}%) in marketing\")\n",
    "    \n",
    "    if fast_development_pct > 50:\n",
    "        print(f\"   • Highlight development speed as key advantage ({fast_development_pct:.1f}% fast development)\")\n",
    "    \n",
    "    strongest_factor = success_correlations.index[0].replace('_', ' ').title()\n",
    "    print(f\"   • Emphasize {strongest_factor} as primary success factor\")\n",
    "    \n",
    "    print(f\"\\n✨ RESEARCH IMPLICATIONS:\")\n",
    "    print(f\"   • Base44 shows {'mature' if high_quality_pct > 25 else 'emerging'} ecosystem characteristics\")\n",
    "    print(f\"   • Platform enables {'rapid' if fast_development_pct > 50 else 'moderate'} development cycles\")\n",
    "    print(f\"   • User satisfaction is {'high' if positive_sentiment_pct > 60 else 'moderate' if positive_sentiment_pct > 40 else 'low'}\")\n",
    "    print(f\"   • Quality distribution suggests {'consistent' if quality_std < 1.5 else 'variable'} user experiences\")\n",
    "    \n",
    "    print(f\"\\n🏁 CONCLUSION:\")\n",
    "    if avg_quality >= 6 and positive_sentiment_pct > 60:\n",
    "        print(f\"   • Base44 demonstrates strong platform performance and user satisfaction\")\n",
    "    elif avg_quality >= 5 or positive_sentiment_pct > 50:\n",
    "        print(f\"   • Base44 shows promising platform performance with room for improvement\")\n",
    "    else:\n",
    "        print(f\"   • Base44 is in early development stage with significant growth potential\")\n",
    "    \n",
    "    print(f\"   • The visualizations support the hypothesis that Base44 is a phenomenon in no-code development\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot generate insights without data. Please run previous notebooks first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This comprehensive visualization notebook has created a complete portfolio of charts, graphs, and interactive dashboards for the Base44 phenomenon analysis.\n",
    "\n",
    "### Visualization Outputs:\n",
    "\n",
    "#### Interactive Dashboards:\n",
    "1. **Executive Dashboard** - High-level overview for stakeholders\n",
    "2. **Comprehensive Dashboard** - Detailed analysis with multiple views\n",
    "3. **Individual Charts** - Focused analysis on specific aspects\n",
    "\n",
    "#### Publication-Ready Figures:\n",
    "1. **Ecosystem Analysis** - Purpose, industry, and complexity patterns\n",
    "2. **Quality Analysis** - Quality metrics and success factors\n",
    "3. **Word Clouds** - Textual analysis of descriptions\n",
    "4. **Network Graphs** - Ecosystem relationships\n",
    "\n",
    "#### Key Visualization Insights:\n",
    "- **Application Distribution**: Clear patterns in purpose and industry usage\n",
    "- **Quality Patterns**: Identification of success factors and quality drivers\n",
    "- **Platform Performance**: Evidence of development speed advantages\n",
    "- **User Sentiment**: Overall positive reception and satisfaction\n",
    "- **Ecosystem Maturity**: Signs of a developing but promising platform\n",
    "\n",
    "### Research Value:\n",
    "These visualizations provide empirical evidence for the Base44 phenomenon, supporting academic research with:\n",
    "- **Quantitative Analysis**: Statistical evidence of platform adoption\n",
    "- **Pattern Recognition**: Clear trends and relationships in the data\n",
    "- **Comparative Analysis**: Benchmarking across categories and metrics\n",
    "- **Visual Evidence**: Publication-ready figures for academic papers\n",
    "\n",
    "### Files Generated:\n",
    "- **HTML Files**: Interactive dashboards and charts\n",
    "- **PNG Files**: High-resolution static images for publications\n",
    "- **Summary File**: Complete visualization index\n",
    "\n",
    "### Next Steps:\n",
    "1. **Academic Paper** - Use these visualizations in the research publication\n",
    "2. **Presentation** - Create slides using the generated charts\n",
    "3. **Further Analysis** - Identify areas for additional research\n",
    "\n",
    "The visualization analysis demonstrates that Base44 has indeed become a phenomenon in the no-code development space, with clear patterns of adoption, quality, and user satisfaction that merit academic study and business attention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}